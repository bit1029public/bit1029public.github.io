---
title: Bulletin
icon: fa-lightbulb
order: 3
---

<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>10/2022:</b> Collaborating with Mila and MSR, we submitted a RL paper to <font size="5" color="red" face="黑体">AISTATS 2022</font>.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>10/2022:</b> Two RL paper are submitted to <font size="5" color="red" face="黑体">ICLR 2023</font>.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>10/2022:</b> Our collaborative paper<a href="https://openreview.net/forum?id=0pFzg-8y-o&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DNeurIPS.cc%2F2022%2FWorkshop%2FOffline_RL%2FAuthors%23your-submissions)" style="color: green;"> [Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information]</a> got accepted for Offline RL Workshop <font size="5" color="red" face="黑体">NeurIPS 2022</font>.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>12/2021:</b> Congratulations to Hongyu Zang. Our paper<a href="https://arxiv.org/abs/2112.15303" style="color: green;">[SimSR: Simple Distance-based State Representation for Deep Reinforcement Learning]</a> got accepted for <font size="5" color="red" face="黑体">AAAI 2022</font>.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>09/2021:</b> Congratulations to Zhang Li. Our paper<a href="[Off-Policy Differentiable Logic Reinforcement Learning]" style="color: green;"> https://2021.ecmlpkdd.org/wp-content/uploads/2021/07/sub_49.pdf</a> got accepted for <font size="5" color="red" face="黑体">ECML-PKDD 2021</font>.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>05/2020:</b> Another work related to POMDP tasks<a href="https://ieeexplore.ieee.org/document/9172883" style="color: green;"> [On Improving the Learning of Long-Term historical Information for Tasks with Partial Observability]</a> is published.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>05/2020:</b> A RL paper is submitted to <font size="5" color="red" face="黑体">NeurIPS 2020</font>.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>04/2020:</b> Collaborating with Ubisoft, we organized some competitions to test our RL agent in Rabbids: Journey To The West, and our RL agent won all the games.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>02/2020:</b> Zhang Li gives the oral presentation of our UVIN paper in<a href="https://www.youtube.com/watch?v=18IqLrK2ugI&feature=share&fbclid=IwAR3kpUv8H4NQlz3lNl-kZCTI5RD2Ryr3VnlH_4O_32ADt5SwTcqapjX7ryY" style="color: green;"> [a recorded video]</a> at <font size="5" color="red" face="黑体">AAAI2020</font> due to the COVID-19 pandemic.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>12/2019:</b> The students won the best technical award in the Data Hackathon competition hosted by Ubisoft.
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>12/2019:</b> Congratulations to Zhang Li. Our<a href="https://aaai.org/ojs/index.php/AAAI/article/view/6157" style="color: green;"> [UVIN paper]</a> got accepted for <font size="5" color="red" face="黑体">AAAI 2020</font> <font size="5" color="#8A2BE2" face="黑体">oral</font> presenations. 
</li>
<li style="text-align:left;font-family:Cormorant SC;font-size:26px">
	<b>04/2017:</b> The group submit our ADRQN paper named<a href="https://arxiv.org/abs/1704.07978" style="color: green;"> [On Improving Deep Reinforcement Learning for POMDPs]</a> to Arxiv <font size="5" color="#8A2BE2" face="黑体">(cited over 65 times)</font>.
</li>